// services/openaiService.js

const OpenAI = require("openai");

class OpenAIService {
  constructor() {
    this.client = null;
    this.model = process.env.OPENAI_MODEL || "gpt-3.5-turbo";
    this.maxTokens = parseInt(process.env.OPENAI_MAX_TOKENS) || 1000;
    this.pricing = {
      "gpt-3.5-turbo": { input: 0.0005, output: 0.0015 },
      "gpt-4": { input: 0.03, output: 0.06 },
      "gpt-4-turbo": { input: 0.01, output: 0.03 },
      "gpt-4o": { input: 0.005, output: 0.015 },
      "gpt-4o-mini": { input: 0.00015, output: 0.0006 },
    };
  }

  /**
   * Initialize OpenAI client
   */
  initialize() {
    if (!this.client && process.env.OPENAI_API_KEY) {
      this.client = new OpenAI({
        apiKey: process.env.OPENAI_API_KEY,
      });
    }
    return this.client;
  }

  /**
   * Check if service is configured
   */
  isConfigured() {
    return !!process.env.OPENAI_API_KEY;
  }

  /**
   * Get system prompt - Enhanced for better understanding and responses
   */
  getSystemPrompt() {
    return `B·∫°n l√† tr·ª£ l√Ω AI th√¥ng minh c·ªßa h·ªá th·ªëng qu·∫£n l√Ω H·ªôi D√≤ng Th√°nh Phaol√¥ Thi·ªán B·∫£n.

## VAI TR√í V√Ä NHI·ªÜM V·ª§
1. Tr·∫£ l·ªùi c√°c c√¢u h·ªèi v·ªÅ n·ªØ tu, h√†nh tr√¨nh ∆°n g·ªçi, c·ªông ƒëo√†n m·ªôt c√°ch CH√çNH X√ÅC d·ª±a tr√™n d·ªØ li·ªáu ƒë∆∞·ª£c cung c·∫•p
2. Gi·∫£i th√≠ch th√¥ng tin r√µ r√†ng, d·ªÖ hi·ªÉu, c√≥ c·∫•u tr√∫c
3. S·ª≠ d·ª•ng ng√¥n ng·ªØ t√¥n tr·ªçng, l·ªãch s·ª±, ph√π h·ª£p v·ªõi m√¥i tr∆∞·ªùng t√¥n gi√°o
4. N·∫øu kh√¥ng c√≥ ƒë·ªß th√¥ng tin, h√£y th√†nh th·∫≠t n√≥i r·∫±ng b·∫°n kh√¥ng c√≥ d·ªØ li·ªáu v√† ƒë·ªÅ xu·∫•t c√°ch kh√°c
5. Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát t·ª± nhi√™n

## C√ÅC GIAI ƒêO·∫†N ∆†N G·ªåI (theo th·ª© t·ª±)
1. **T√¨m hi·ªÉu (Inquiry)**: Giai ƒëo·∫°n ƒë·∫ßu ti√™n khi t√¨m hi·ªÉu v·ªÅ ƒë·ªùi tu
2. **Ti·ªÅn t·∫≠p vi·ªán (Pre-postulancy)**: Chu·∫©n b·ªã tr∆∞·ªõc khi v√†o t·∫≠p vi·ªán  
3. **T·∫≠p vi·ªán (Postulancy)**: Giai ƒëo·∫°n t·∫≠p vi·ªán, h·ªçc h·ªèi cƒÉn b·∫£n
4. **Nh√† t·∫≠p (Novitiate)**: Giai ƒëo·∫°n nh√† t·∫≠p, h·ªçc h·ªèi s√¢u h∆°n v·ªÅ ƒë·ªùi tu
5. **Kh·∫•n t·∫°m (Temporary Vows)**: ƒê√£ kh·∫•n l·∫ßn ƒë·∫ßu, cam k·∫øt t·∫°m th·ªùi (th∆∞·ªùng 3-6 nƒÉm)
6. **Kh·∫•n tr·ªçn (Perpetual Vows)**: Kh·∫•n vƒ©nh vi·ªÖn, cam k·∫øt tr·ªçn ƒë·ªùi

## C√ÅCH TR·∫¢ L·ªúI
- **C√¢u h·ªèi v·ªÅ s·ªë l∆∞·ª£ng**: Tr·∫£ l·ªùi s·ªë li·ªáu c·ª• th·ªÉ tr∆∞·ªõc, sau ƒë√≥ gi·∫£i th√≠ch th√™m n·∫øu c·∫ßn
- **C√¢u h·ªèi v·ªÅ th√¥ng tin c√° nh√¢n**: Tr√¨nh b√†y c√≥ c·∫•u tr√∫c v·ªõi c√°c m·ª•c r√µ r√†ng
- **C√¢u h·ªèi v·ªÅ danh s√°ch**: S·ª≠ d·ª•ng bullet points ho·∫∑c ƒë√°nh s·ªë
- **C√¢u h·ªèi so s√°nh**: S·ª≠ d·ª•ng b·∫£ng ho·∫∑c so s√°nh song song
- **C√¢u h·ªèi kh√¥ng r√µ r√†ng**: H·ªèi l·∫°i ƒë·ªÉ l√†m r√µ thay v√¨ ƒëo√°n

## QUY T·∫ÆC QUAN TR·ªåNG
1. KH√îNG b·ªãa ƒë·∫∑t th√¥ng tin - ch·ªâ d·ª±a tr√™n d·ªØ li·ªáu ƒë∆∞·ª£c cung c·∫•p
2. N·∫øu d·ªØ li·ªáu l√† "N/A" ho·∫∑c tr·ªëng, n√≥i r√µ "Ch∆∞a c√≥ th√¥ng tin" thay v√¨ b·ªè qua
3. S·ª≠ d·ª•ng emoji ph√π h·ª£p ƒë·ªÉ l√†m c√¢u tr·∫£ l·ªùi sinh ƒë·ªông (üë§ üìç üìä üè† üìö ‚úÖ ‚ùå)
4. Khi ƒë·ªÅ c·∫≠p ƒë·∫øn ng∆∞·ªùi, d√πng "Ch·ªã" ho·∫∑c t√™n th√°nh ƒëi k√®m t√™n
5. Format ng√†y th√°ng theo ki·ªÉu Vi·ªát Nam (DD/MM/YYYY)
6. V·ªõi s·ªë li·ªáu, l√†m tr√≤n v√† th√™m ƒë∆°n v·ªã r√µ r√†ng

## X·ª¨ L√ù C√ÇU H·ªéI PH·ª®C T·∫†P
- N·∫øu c√¢u h·ªèi c√≥ nhi·ªÅu ph·∫ßn, tr·∫£ l·ªùi t·ª´ng ph·∫ßn m·ªôt c√°ch r√µ r√†ng
- N·∫øu c√¢u h·ªèi m∆° h·ªì, x√°c nh·∫≠n l·∫°i √Ω ng∆∞·ªùi d√πng
- N·∫øu kh√¥ng t√¨m th·∫•y ch√≠nh x√°c, g·ª£i √Ω k·∫øt qu·∫£ t∆∞∆°ng t·ª±`;
  }

  /**
   * Chat with OpenAI
   */
  async chat(userMessage, context = null, conversationHistory = []) {
    try {
      // Initialize client if not already
      if (!this.initialize()) {
        return {
          success: false,
          message:
            "D·ªãch v·ª• AI ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh. Vui l√≤ng li√™n h·ªá qu·∫£n tr·ªã vi√™n.",
          error: "OpenAI API key not configured",
        };
      }

      // Build messages array
      const messages = [
        {
          role: "system",
          content: this.getSystemPrompt(),
        },
      ];

      // Add conversation history (last 10 messages for context)
      if (conversationHistory.length > 0) {
        const recentHistory = conversationHistory.slice(-10);
        recentHistory.forEach((msg) => {
          messages.push({
            role: msg.role === "user" ? "user" : "assistant",
            content: msg.content,
          });
        });
      }

      // Add context from database with clear formatting
      if (context && context.text) {
        messages.push({
          role: "system",
          content: `## D·ªÆ LI·ªÜU T·ª™ H·ªÜ TH·ªêNG\nƒê√¢y l√† d·ªØ li·ªáu th·ª±c t·∫ø t·ª´ c∆° s·ªü d·ªØ li·ªáu. H√£y d·ª±a v√†o d·ªØ li·ªáu n√†y ƒë·ªÉ tr·∫£ l·ªùi:\n\n${context.text}`,
        });
      }

      // Add user message
      messages.push({
        role: "user",
        content: userMessage,
      });

      // Call OpenAI API with optimized settings
      const completion = await this.client.chat.completions.create({
        model: this.model,
        messages: messages,
        max_tokens: this.maxTokens,
        temperature: 0.7,
        top_p: 0.95,
        frequency_penalty: 0.1,
        presence_penalty: 0.1,
      });

      const response = completion.choices[0].message.content;
      const usage = completion.usage;

      // Calculate cost
      const cost = this.calculateCost(usage);

      return {
        success: true,
        message: response,
        tokens: usage.total_tokens,
        promptTokens: usage.prompt_tokens,
        completionTokens: usage.completion_tokens,
        cost: cost,
        model: this.model,
        context: context,
      };
    } catch (error) {
      console.error("OpenAI API Error:", error.message);

      // Handle quota exceeded - return context-based response
      if (error.status === 429 || error.code === "insufficient_quota") {
        // Fallback: return context data directly
        if (context && context.text) {
          return {
            success: true,
            message: `‚ö†Ô∏è *Ch·∫ø ƒë·ªô offline - D·ªØ li·ªáu t·ª´ h·ªá th·ªëng:*\n\n${context.text}\n\n_L∆∞u √Ω: AI ƒëang t·∫°m ng∆∞ng, ƒë√¢y l√† d·ªØ li·ªáu tr·ª±c ti·∫øp t·ª´ database._`,
            tokens: 0,
            cost: 0,
            model: "offline-fallback",
          };
        }
        return {
          success: false,
          message:
            "‚ö†Ô∏è H·ªá th·ªëng AI ƒë√£ h·∫øt quota. Vui l√≤ng li√™n h·ªá qu·∫£n tr·ªã vi√™n ƒë·ªÉ n·∫°p th√™m credit OpenAI.",
          error: error.message,
        };
      }

      if (error.code === "rate_limit_exceeded") {
        return {
          success: false,
          message: "H·ªá th·ªëng ƒëang b·∫≠n, vui l√≤ng th·ª≠ l·∫°i sau v√†i gi√¢y.",
          error: error.message,
        };
      }

      return {
        success: false,
        message:
          "Xin l·ªói, t√¥i kh√¥ng th·ªÉ x·ª≠ l√Ω y√™u c·∫ßu c·ªßa b·∫°n l√∫c n√†y. Vui l√≤ng th·ª≠ l·∫°i sau.",
        error: error.message,
      };
    }
  }

  /**
   * Calculate cost based on token usage
   */
  calculateCost(usage) {
    const pricing = this.pricing[this.model];

    if (!pricing) {
      return 0;
    }

    const inputCost = (usage.prompt_tokens / 1000) * pricing.input;
    const outputCost = (usage.completion_tokens / 1000) * pricing.output;

    return parseFloat((inputCost + outputCost).toFixed(6));
  }

  /**
   * Get model info
   */
  getModelInfo() {
    return {
      model: this.model,
      maxTokens: this.maxTokens,
      pricing: this.pricing[this.model] || null,
      isConfigured: this.isConfigured(),
    };
  }

  /**
   * Analyze user message using AI to extract intent and entities
   * This is the FIRST step - let AI understand the question before database queries
   */
  async analyzeWithAI(userMessage) {
    try {
      if (!this.initialize()) {
        console.log("OpenAI not configured, falling back to keyword analysis");
        return null;
      }

      const analysisPrompt = `Ph√¢n t√≠ch c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng v√† tr·∫£ v·ªÅ JSON v·ªõi c√°c tr∆∞·ªùng sau:

INTENT (ch·ªçn 1):
- "sister_info": H·ªèi v·ªÅ th√¥ng tin n·ªØ tu c·ª• th·ªÉ (t√™n, tu·ªïi, ng√†y sinh, c·ªông ƒëo√†n...)
- "community_info": H·ªèi v·ªÅ c·ªông ƒëo√†n (danh s√°ch, th√¥ng tin, th√†nh vi√™n...)
- "statistics": H·ªèi v·ªÅ s·ªë l∆∞·ª£ng, th·ªëng k√™ (bao nhi√™u, m·∫•y, t·ªïng s·ªë...)
- "journey_info": H·ªèi v·ªÅ h√†nh tr√¨nh ∆°n g·ªçi, giai ƒëo·∫°n tu (kh·∫•n, nh√† t·∫≠p...)
- "education_info": H·ªèi v·ªÅ h·ªçc v·∫•n, b·∫±ng c·∫•p
- "health_info": H·ªèi v·ªÅ s·ª©c kh·ªèe
- "mission_info": H·ªèi v·ªÅ s·ª© v·ª•, c√¥ng t√°c
- "help": H·ªèi c√°ch s·ª≠ d·ª•ng, h∆∞·ªõng d·∫´n
- "greeting": Ch√†o h·ªèi ƒë∆°n gi·∫£n
- "general": C√¢u h·ªèi chung kh√°c

ENTITIES (tr√≠ch xu·∫•t n·∫øu c√≥):
- person_name: T√™n ng∆∞·ªùi ƒë∆∞·ª£c h·ªèi (VD: "Nguy·ªÖn Th·ªã Mai", "Maria", "s∆° T√≠n")
- community_name: T√™n c·ªông ƒëo√†n (VD: "S√†i G√≤n", "Th·ªß ƒê·ª©c")
- stage: Giai ƒëo·∫°n ∆°n g·ªçi (inquiry, postulancy, novitiate, temporary_vows, perpetual_vows)
- age_question: true n·∫øu h·ªèi v·ªÅ tu·ªïi
- count_question: true n·∫øu h·ªèi v·ªÅ s·ªë l∆∞·ª£ng
- list_question: true n·∫øu h·ªèi danh s√°ch

C√¢u h·ªèi: "${userMessage}"

Tr·∫£ v·ªÅ CH√çNH X√ÅC JSON format (kh√¥ng markdown):
{"intent":"...", "entities":{"person_name":"...", ...}, "keywords":["keyword1","keyword2"]}`;

      const completion = await this.client.chat.completions.create({
        model: this.model,
        messages: [
          {
            role: "system",
            content:
              "B·∫°n l√† AI ph√¢n t√≠ch c√¢u h·ªèi. Ch·ªâ tr·∫£ v·ªÅ JSON, kh√¥ng gi·∫£i th√≠ch.",
          },
          {
            role: "user",
            content: analysisPrompt,
          },
        ],
        max_tokens: 300,
        temperature: 0.1, // Low temperature for consistent parsing
      });

      const responseText = completion.choices[0].message.content.trim();
      console.log("AI Analysis raw response:", responseText);

      // Parse JSON from response (handle potential markdown wrapper)
      let jsonStr = responseText;
      if (responseText.includes("```json")) {
        jsonStr =
          responseText.match(/```json\s*([\s\S]*?)\s*```/)?.[1] || responseText;
      } else if (responseText.includes("```")) {
        jsonStr =
          responseText.match(/```\s*([\s\S]*?)\s*```/)?.[1] || responseText;
      }

      const analysis = JSON.parse(jsonStr);
      console.log("AI Analysis parsed:", analysis);

      return {
        success: true,
        intent: analysis.intent || "general",
        entities: analysis.entities || {},
        keywords: analysis.keywords || [],
        confidence: 0.9, // AI analysis has high confidence
        source: "ai",
      };
    } catch (error) {
      console.error("AI Analysis error:", error.message);
      return null; // Return null to fall back to keyword analysis
    }
  }
}

module.exports = new OpenAIService();
